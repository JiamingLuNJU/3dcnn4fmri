{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hailey/anaconda3/envs/env_for_notebook/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hailey/anaconda3/envs/env_for_notebook/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hailey/anaconda3/envs/env_for_notebook/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hailey/anaconda3/envs/env_for_notebook/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hailey/anaconda3/envs/env_for_notebook/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hailey/anaconda3/envs/env_for_notebook/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/hailey/anaconda3/envs/env_for_notebook/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vols = sio.loadmat('./sensorimotor_4D_sample.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = vols['X_train'], vols['X_test'], vols['y_train'], vols['y_test']\n",
    "n_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1320, 53, 63, 46) (120, 53, 63, 46) (1320, 1) (120, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train),np.shape(X_test),np.shape(y_train),np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [0],\n",
       "       ...,\n",
       "       [3],\n",
       "       [2],\n",
       "       [3]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### z-scoring to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = np.mean(X_train)\n",
    "x_std = np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_centered = (X_train - x_mean)/x_std\n",
    "X_ts_centered = (X_test - x_mean)/x_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D array for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking out the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1320, 53, 63, 46), (120, 53, 63, 46))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_centered.shape,  X_ts_centered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0094781412712692"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(X_ts_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking out the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_tr_centered[1,:,:,40])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch generator: to generate mini-batches for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size=50, \n",
    "                    shuffle=True, random_seed=None):\n",
    "    \n",
    "    idx = np.arange(y.shape[0])\n",
    "    \n",
    "    if shuffle:\n",
    "        rng = np.random.RandomState(random_seed)\n",
    "        rng.shuffle(idx)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "    \n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        yield (X[i:i+batch_size, :], y[i:i+batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D-CNN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3dNN(object):\n",
    "    def __init__(self, n_classes=4, batchsize=50,\n",
    "                 epochs=100, learning_rate=1e-4, \n",
    "                 dropout_rate=0.5,\n",
    "                 shuffle=True, random_seed=None):\n",
    "        np.random.seed(random_seed)\n",
    "        self.batchsize = batchsize\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.shuffle = shuffle\n",
    "        self.n_classes = n_classes\n",
    "                \n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            ## set random-seed:\n",
    "            tf.set_random_seed(random_seed)\n",
    "            \n",
    "            ## build the network:\n",
    "            self.build()\n",
    "\n",
    "            ## initializer\n",
    "            self.init_op = \\\n",
    "                tf.global_variables_initializer()\n",
    "\n",
    "            ## saver\n",
    "            self.saver = tf.train.Saver()\n",
    "            \n",
    "        ## create a session\n",
    "        self.sess = tf.Session(graph=g)\n",
    "                \n",
    "    def build(self):\n",
    "        \n",
    "        ## Placeholders for X and y:\n",
    "        tf_x = tf.placeholder(tf.float32, \n",
    "                              shape=[None, 53, 63, 46],\n",
    "                              name='tf_x')\n",
    "        tf_y = tf.placeholder(tf.int32, \n",
    "                              shape=[None],\n",
    "                              name='tf_y')\n",
    "        is_train = tf.placeholder(tf.bool, \n",
    "                              shape=(),\n",
    "                              name='is_train')\n",
    "        \n",
    "        ## reshape x to 5D tensor:\n",
    "        ## [batchsize, x, y, z, 1]\n",
    "        tf_x_vol = tf.reshape(tf_x, shape=[-1, 53, 63, 46, 1],\n",
    "                             name='input_x_3d_volumes')\n",
    "\n",
    "        ## One-hot encoding:\n",
    "        tf_y_onehot = tf.one_hot(indices=tf_y, depth=4,\n",
    "                              dtype=tf.float32,\n",
    "                              name='input_y_onehot')\n",
    "\n",
    "        ## 1st layer: Conv_1\n",
    "        h1 = tf.layers.conv3d(tf_x_vol, \n",
    "                              filters=8, \n",
    "                              kernel_size=(7, 7, 7), \n",
    "                              strides=(1, 1, 1),\n",
    "                              padding='valid',\n",
    "                              activation=tf.nn.relu)\n",
    "        ## MaxPooling\n",
    "        h1_pool = tf.layers.max_pooling3d(h1, \n",
    "                              pool_size=(2, 2, 2), \n",
    "                              strides=(2, 2, 2))\n",
    "        \n",
    "        ## 2nd layer: Conv_2\n",
    "        h2 = tf.layers.conv3d(h1_pool, \n",
    "                              filters=16, \n",
    "                              kernel_size=(5, 5, 5), \n",
    "                              strides=(1,1,1),\n",
    "                              padding='valid',\n",
    "                              activation=tf.nn.relu)\n",
    "        ## MaxPooling \n",
    "        h2_pool = tf.layers.max_pooling3d(h2, \n",
    "                              pool_size=(2, 2, 2), \n",
    "                              strides=(2, 2, 2))\n",
    "\n",
    "        ## 3rd layer: Conv_3\n",
    "        h3 = tf.layers.conv3d(h2_pool, \n",
    "                              filters=32, \n",
    "                              kernel_size=(3, 3, 3), \n",
    "                              strides=(1,1,1),\n",
    "                              padding='valid',\n",
    "                              activation=tf.nn.relu)\n",
    "        ## MaxPooling \n",
    "        h3_pool = tf.layers.max_pooling3d(h3, \n",
    "                              pool_size=(2, 2, 2), \n",
    "                              strides=(2, 2, 2))\n",
    "        \n",
    "        ## 4th layer: Fully Connected\n",
    "        input_shape = h3_pool.get_shape().as_list()\n",
    "        n_input_units = np.prod(input_shape[1:])\n",
    "        h3_pool_flat = tf.reshape(h3_pool, \n",
    "                              shape=[-1, n_input_units])\n",
    "        \n",
    "        h4 = tf.layers.dense(h3_pool_flat, 128, \n",
    "                              activation=tf.nn.relu)\n",
    "\n",
    "        ## Dropout\n",
    "        h4_drop = tf.layers.dropout(h4, \n",
    "                              rate=self.dropout_rate,\n",
    "                              training=is_train)\n",
    "        \n",
    "        ## 5th layer: Fully Connected (linear activation)\n",
    "        h5 = tf.layers.dense(h4_drop, self.n_classes, \n",
    "                              activation=tf.nn.sigmoid)\n",
    "\n",
    "        ## Prediction\n",
    "        predictions = {\n",
    "            'probabilities': tf.nn.softmax(h5, \n",
    "                              name='probabilities'),\n",
    "            'labels': tf.cast(tf.argmax(h5, axis=1), \n",
    "                              tf.int32, name='labels')}\n",
    "        \n",
    "        ## Loss Function and Optimization\n",
    "        cross_entropy_loss = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                logits=h5, labels=tf_y_onehot),\n",
    "            name='cross_entropy_loss')\n",
    "        \n",
    "        ## Optimizer:\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        optimizer = optimizer.minimize(cross_entropy_loss,\n",
    "                              name='train_op')\n",
    "\n",
    "        ## Finding accuracy\n",
    "        correct_predictions = tf.equal(\n",
    "            predictions['labels'], \n",
    "            tf_y, name='correct_preds')\n",
    "        \n",
    "        accuracy = tf.reduce_mean(\n",
    "            tf.cast(correct_predictions, tf.float32),\n",
    "            name='accuracy')\n",
    "\n",
    "    def save(self, epoch, path='./CNN3d-tflayers-model/'):\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path)\n",
    "        print('Saving model in %s' % path)\n",
    "        self.saver.save(self.sess, \n",
    "                        os.path.join(path, 'model.ckpt'),\n",
    "                        global_step=epoch)\n",
    "        \n",
    "    def load(self, epoch, path):\n",
    "        print('Loading model from %s' % path)\n",
    "        self.saver.restore(self.sess, \n",
    "             os.path.join(path, 'model.ckpt-%d' % epoch))\n",
    "        \n",
    "    def train(self, training_set, \n",
    "              validation_set=None,\n",
    "              initialize=True):\n",
    "        ## initialize variables\n",
    "        if initialize:\n",
    "            self.sess.run(self.init_op)\n",
    "\n",
    "        self.train_cost_ = []\n",
    "        X_data_tr = np.array(training_set[0])\n",
    "        y_data_tr = np.array(training_set[1])\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            batch_gen_tr = \\\n",
    "                batch_generator(X_data_tr, y_data_tr, batch_size=self.batchsize, \n",
    "                                 shuffle=self.shuffle)\n",
    "            avg_loss = 0.0\n",
    "            for i, (batch_x,batch_y) in \\\n",
    "                enumerate(batch_gen_tr):\n",
    "                feed = {'tf_x:0': batch_x, \n",
    "                        'tf_y:0': batch_y,\n",
    "                        'is_train:0': True} ## for dropout\n",
    "                loss, _ = self.sess.run(\n",
    "                        ['cross_entropy_loss:0', 'train_op'], \n",
    "                        feed_dict=feed)\n",
    "                avg_loss += loss\n",
    "                \n",
    "            print('Epoch %02d: Training Avg. Loss: '\n",
    "                  '%7.3f' % (epoch, avg_loss), end=' ')\n",
    "            if validation_set is not None:\n",
    "                \n",
    "                X_data_ts = np.array(training_set[0])\n",
    "                y_data_ts = np.array(training_set[1])\n",
    "                # test accuracy\n",
    "                batch_gen_ts = \\\n",
    "                batch_generator(X_data_ts, y_data_ts,\n",
    "                                 shuffle=False,batch_size=self.batchsize)\n",
    "                avg_valid_acc = 0.0\n",
    "                for i, (batch_x,batch_y) in \\\n",
    "                    enumerate(batch_gen_ts):\n",
    "                    feed = {'tf_x:0': batch_x,\n",
    "                            'tf_y:0': batch_y,\n",
    "                            'is_train:0': False} ## for dropout\n",
    "                    avg_valid_acc = avg_valid_acc + self.sess.run('accuracy:0', feed_dict=feed)\n",
    "                avg_valid_acc = avg_valid_acc/(i+1)\n",
    "                \n",
    "                print('Validation Acc: %7.3f' % avg_valid_acc)\n",
    "            else:\n",
    "                print()\n",
    "                    \n",
    "    def predict(self, X_test, return_proba = False):\n",
    "        feed = {'tf_x:0': X_test,\n",
    "                'is_train:0': False} ## for dropout\n",
    "        if return_proba:\n",
    "            return self.sess.run('probabilities:0',\n",
    "                                 feed_dict=feed)\n",
    "        else:\n",
    "            return self.sess.run('labels:0',\n",
    "                                 feed_dict=feed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance of the CNN3dNN class, train it, and save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Training Avg. Loss:  36.404 Validation Acc:   0.609\n",
      "Epoch 02: Training Avg. Loss:  31.540 Validation Acc:   0.856\n",
      "Epoch 03: Training Avg. Loss:  26.874 Validation Acc:   0.914\n",
      "Epoch 04: Training Avg. Loss:  25.061 Validation Acc:   0.932\n",
      "Epoch 05: Training Avg. Loss:  23.826 Validation Acc:   0.950\n",
      "Epoch 06: Training Avg. Loss:  23.189 Validation Acc:   0.949\n",
      "Epoch 07: Training Avg. Loss:  22.600 Validation Acc:   0.961\n",
      "Epoch 08: Training Avg. Loss:  22.299 Validation Acc:   0.967\n",
      "Epoch 09: Training Avg. Loss:  22.072 Validation Acc:   0.970\n",
      "Epoch 10: Training Avg. Loss:  21.772 Validation Acc:   0.972\n",
      "Epoch 11: Training Avg. Loss:  21.623 Validation Acc:   0.972\n",
      "Epoch 12: Training Avg. Loss:  21.513 Validation Acc:   0.979\n",
      "Epoch 13: Training Avg. Loss:  21.484 Validation Acc:   0.981\n",
      "Epoch 14: Training Avg. Loss:  21.349 Validation Acc:   0.981\n",
      "Epoch 15: Training Avg. Loss:  21.248 Validation Acc:   0.979\n",
      "Epoch 16: Training Avg. Loss:  21.229 Validation Acc:   0.984\n",
      "Epoch 17: Training Avg. Loss:  21.346 Validation Acc:   0.987\n",
      "Epoch 18: Training Avg. Loss:  21.110 Validation Acc:   0.982\n",
      "Epoch 19: Training Avg. Loss:  20.899 Validation Acc:   0.984\n",
      "Epoch 20: Training Avg. Loss:  20.837 Validation Acc:   0.988\n",
      "Epoch 21: Training Avg. Loss:  20.806 Validation Acc:   0.985\n",
      "Epoch 22: Training Avg. Loss:  20.763 Validation Acc:   0.987\n",
      "Epoch 23: Training Avg. Loss:  20.758 Validation Acc:   0.991\n",
      "Epoch 24: Training Avg. Loss:  20.731 Validation Acc:   0.990\n",
      "Epoch 25: Training Avg. Loss:  20.726 Validation Acc:   0.990\n",
      "Epoch 26: Training Avg. Loss:  20.657 Validation Acc:   0.993\n",
      "Epoch 27: Training Avg. Loss:  20.742 Validation Acc:   0.993\n",
      "Epoch 28: Training Avg. Loss:  20.608 Validation Acc:   0.987\n",
      "Epoch 29: Training Avg. Loss:  20.612 Validation Acc:   0.993\n",
      "Epoch 30: Training Avg. Loss:  20.573 Validation Acc:   0.993\n",
      "Epoch 31: Training Avg. Loss:  20.614 Validation Acc:   0.994\n",
      "Epoch 32: Training Avg. Loss:  20.595 Validation Acc:   0.995\n",
      "Epoch 33: Training Avg. Loss:  20.507 Validation Acc:   0.993\n",
      "Epoch 34: Training Avg. Loss:  20.517 Validation Acc:   0.993\n",
      "Epoch 35: Training Avg. Loss:  20.420 Validation Acc:   0.998\n",
      "Epoch 36: Training Avg. Loss:  20.452 Validation Acc:   0.994\n",
      "Epoch 37: Training Avg. Loss:  20.473 Validation Acc:   0.997\n",
      "Epoch 38: Training Avg. Loss:  20.504 Validation Acc:   0.998\n",
      "Epoch 39: Training Avg. Loss:  20.423 Validation Acc:   0.999\n",
      "Epoch 40: Training Avg. Loss:  20.454 Validation Acc:   0.996\n",
      "Epoch 41: Training Avg. Loss:  20.388 Validation Acc:   0.998\n",
      "Epoch 42: Training Avg. Loss:  20.376 Validation Acc:   0.997\n",
      "Epoch 43: Training Avg. Loss:  20.384 Validation Acc:   1.000\n",
      "Epoch 44: Training Avg. Loss:  20.287 Validation Acc:   0.999\n",
      "Epoch 45: Training Avg. Loss:  20.387 Validation Acc:   0.998\n",
      "Epoch 46: Training Avg. Loss:  20.370 Validation Acc:   1.000\n",
      "Epoch 47: Training Avg. Loss:  20.367 Validation Acc:   0.995\n",
      "Epoch 48: Training Avg. Loss:  20.317 Validation Acc:   0.999\n",
      "Epoch 49: Training Avg. Loss:  20.289 Validation Acc:   1.000\n",
      "Epoch 50: Training Avg. Loss:  20.301 Validation Acc:   1.000\n",
      "Saving model in ./CNN3d-tflayers-model/\n"
     ]
    }
   ],
   "source": [
    "cnn3d = Conv3dNN(random_seed=123, epochs=50, n_classes=n_classes)\n",
    "\n",
    "cnn3d.train(training_set=(X_tr_centered, y_train), \n",
    "         validation_set=(X_ts_centered, y_test))\n",
    "\n",
    "cnn3d.save(epoch=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To load the trained model and to test it using data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./CNN3d-tflayers-model/\n",
      "INFO:tensorflow:Restoring parameters from ./CNN3d-tflayers-model/model.ckpt-50\n",
      "[3 2 2 0 3 2 3 3 1 1]\n"
     ]
    }
   ],
   "source": [
    "del cnn3d\n",
    "\n",
    "cnn3d_re = Conv3dNN(random_seed=123)\n",
    "cnn3d_re.load(epoch=50, path='./CNN3d-tflayers-model/')\n",
    "\n",
    "print(cnn3d_re.predict(X_ts_centered[:10,:,:,:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuray for all test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "preds = cnn3d_re.predict(X_ts_centered)\n",
    "\n",
    "print('Test Accuracy: {:.2f}'.format( 100 * np.sum(y_test == preds)/len(y_test)))"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
